{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c447b349-1341-4037-810a-1dcc66d3434a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src = \"https://drive.google.com/uc?export=view&id=1O_GIqeNM4LCwbcoN9tVKHbW3UR_N9yDu\">\n",
    "\n",
    "# Thesis: Segmentation of Electron Microscopy Kidney Biopsy Images\n",
    "<b>Name</b>: Aristotelis Styanidis |\n",
    "<b>Date</b>: January 2023\n",
    "---\n",
    "This document is structured as follows:\n",
    "* [Importing packages](#Importing-packages)\n",
    "* [I. Loading Data](#I.-Loading-Data) \n",
    "* [II. Data Preprocessing](#II.-Data-Preprocessing)\n",
    "* [III. Dataset and DataLoader](#III.-Dataset-and-DataLoader)\n",
    "* [IV. The Model](#IV.-The-Model)\n",
    "* [V. Loss function and Optimizer](#V.-Loss-function-and-Optimizer)\n",
    "* [VI. Saving the model](#VI.-Saving-the-model)\n",
    "* [VII. Training and evaluating the model](#VII.-Training-and-evaluating-the-model)\n",
    "* [VIII. Testing the model on the test data](#VIII.-Testing-the-model-on-the-test-data)\n",
    "* [IX. Results](#IX.-Results)\n",
    "\n",
    "This template notebook demonstrates the required steps in order to train and evaluate a U-Net model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae4b3d-a525-4e77-b52f-4627cfacc0f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing packages\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5038bb01-190b-4c58-8d9d-0a6378760695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgi import test\n",
    "import time\n",
    "import enum\n",
    "from json import load\n",
    "from operator import index\n",
    "import os\n",
    "from cv2 import imshow\n",
    "from matplotlib import image \n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "from albumentations import HorizontalFlip, VerticalFlip, Rotate, Transpose, GaussNoise\n",
    "from patchify import patchify, unpatchify\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b011999-82ef-4f8a-8695-1712ab2f6f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from model import build_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "552e5940-0ca0-45d4-8ba4-e7fc00f856f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import epoch_time, get_image_names, get_paths, seeding, rgb2mask\n",
    "from model import build_unet\n",
    "import albumentations as A\n",
    "from loss import DiceLoss, DiceBCELoss, CELoss\n",
    "from data import CustomDataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa931099-a47a-483e-8b8c-632d5fa6cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: background, 1: podocytes, 2: gbm\n",
    "LABEL_TO_COLOR = {0:[0,0,0], 1:[0,255,0], 2:[255,0,0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c163d66-56a6-4a02-a781-ab0a63b76576",
   "metadata": {},
   "source": [
    "## I. Loading Data\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13c090d-674c-437f-aad3-c781245d15d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 10\n",
      "Number of RGB Masks: 10\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Seeding \"\"\"\n",
    "seeding(42)\n",
    "\n",
    "\"\"\" Loading the original images and masks \"\"\"\n",
    "path = \"../dataset\"\n",
    "\n",
    "images = np.array(sorted(glob(os.path.join(path, \"images\", \"*.tif\"))))\n",
    "masks = np.array(sorted(glob(os.path.join(path, \"masks_rgb\", \"*.png\"))))\n",
    "\n",
    "print(f\"Number of Images: {len(images)}\")\n",
    "print(f\"Number of RGB Masks: {len(masks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d303c-d838-485e-add2-de027ce69a83",
   "metadata": {},
   "source": [
    "## II. Data Preprocessing\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ca949c-c689-4bc5-8401-125e279e1b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Cropping the image on the x-axis \"\"\"\n",
    "def crop_image(img, x_min, x_max):\n",
    "    cropped_img = img[:, x_min:x_max]\n",
    "    return cropped_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58dbb44a-042e-4cd9-9074-d4b823b08fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Creating and saving patches to a new directory \"\"\"\n",
    "def create_patches(images, masks, save_path, patch_size = 512):\n",
    "    size = (3584, 3072)\n",
    "\n",
    "    for idx, (x, y) in tqdm(enumerate(zip(images, masks)), total=len(images)):\n",
    "        \n",
    "        \"\"\" Extracting the name \"\"\"\n",
    "        name = x.split(\"/\")[-1].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "        \"\"\" Reading Image and Mask \"\"\"\n",
    "        # Reads image as a grayscale image\n",
    "        x = cv.imread(x, 0)\n",
    "        \n",
    "        # Reads mask as a rgb image\n",
    "        y = cv.imread(y, 1)\n",
    "        \n",
    "        \n",
    "        \"\"\" Cropping Image \"\"\"\n",
    "        # Crops the image in order to fit \n",
    "        # with the Unet input dimensions\n",
    "        crop_image(x, 128, 3712)\n",
    "        crop_image(y, 128, 3712)\n",
    "\n",
    "        \n",
    "        i_patches = patchify(x, (patch_size, patch_size), step=patch_size)\n",
    "        m_patches = patchify(y, (patch_size, patch_size, 3), step=patch_size)\n",
    "\n",
    "        \"\"\" Spliting image into patches \"\"\"\n",
    "        for k in range(i_patches.shape[0]):\n",
    "            for l in range(i_patches.shape[1]):\n",
    "                tmp_image_name = f\"{name}\" + \"_\" + str(k) + \"_\" + str(l) + \".png\"\n",
    "                tmp_mask_name = f\"{name}\" + \"_\" + str(k) + \"_\" + str(l) + \" - rgb_mask.png\"\n",
    "\n",
    "                image_path = os.path.join(save_path, \"images\", tmp_image_name)\n",
    "                mask_path = os.path.join(save_path, \"masks\", tmp_mask_name)\n",
    "\n",
    "                cv.imwrite(image_path, i_patches[k, l, :, :])\n",
    "                cv.imwrite(mask_path, m_patches[k, l, 0, :, :,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f40deb-f482-4c1e-82db-6fc0ee8b46fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to create and save the patches\n",
    "# create_patches(images_paths, masks_paths, \"C:/Users/Aristotelis/src/Thesis_src/dataset_patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece80fd6-8a96-477e-8d8d-18200487edad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image patches: 420\n",
      "Number of rgb mask patches: 420\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Loading the image and mask patches \"\"\"\n",
    "path = \"../dataset_patches\"\n",
    "\n",
    "image_patches = np.array(sorted(glob(os.path.join(path, \"images\", \"*.png\"))))\n",
    "mask_patches = np.array(sorted(glob(os.path.join(path, \"masks\", \"*.png\"))))\n",
    "\n",
    "print(f\"Number of image patches: {len(image_patches)}\")\n",
    "print(f\"Number of rgb mask patches: {len(mask_patches)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd32cf-cb32-4997-b881-f33c6928798e",
   "metadata": {},
   "source": [
    "### K - Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f7640a4-d6f2-4913-ba0e-b380eff6ca57",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Fold 1\n",
      "Train: [7 2 8 3 9] Valid: [6 5 4] Test:  [0 1]\n",
      "----------------------------------------------------------\n",
      "Fold 2\n",
      "Train: [7 0 8 1 9] Valid: [6 5 4] Test:  [2 3]\n",
      "----------------------------------------------------------\n",
      "Fold 3\n",
      "Train: [7 0 8 1 9] Valid: [6 3 2] Test:  [4 5]\n",
      "----------------------------------------------------------\n",
      "Fold 4\n",
      "Train: [5 0 8 1 9] Valid: [4 3 2] Test:  [6 7]\n",
      "----------------------------------------------------------\n",
      "Fold 5\n",
      "Train: [5 0 6 1 7] Valid: [4 3 2] Test:  [8 9]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" K - Fold Split (5 - Fold) \"\"\"\n",
    "\n",
    "# prepare cross validation\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "i = 0\n",
    "# enumerate splits\n",
    "for tmp_train, tmp_test in kfold.split(images):\n",
    "    train_set, valid_set = train_test_split(tmp_train, test_size=0.3, random_state=17)\n",
    "    test_set = tmp_test\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(\"Fold\", i + 1)\n",
    "    print(\"Train:\", train_set, \"Valid:\", valid_set, \"Test: \", test_set)\n",
    "    i = i + 1\n",
    "    # uncomment break in case you want to run only for one fold\n",
    "    if i == 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eedaaacd-50f4-4996-ba38-baebe63bc598",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset\\\\images\\\\20B794  foto 12  3000x.tif'\n",
      " '../dataset\\\\images\\\\20B9593  foto 1  3000x.tif']\n"
     ]
    }
   ],
   "source": [
    "print(images[test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8a69b4-d274-4b38-b524-bffccad009b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = get_image_names(images, train_set)\n",
    "valid_images = get_image_names(images, valid_set)\n",
    "test_images = get_image_names(images, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f64ef65-2d6b-4639-a2dd-d2cd4ce07e94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Images:\n",
      " ['20B6215  foto 11  3000x', '20B10793  foto 14  3000x', '20B6494  foto 4  3000x', '20B13170  foto 3  3000x', '20B6652  foto 2  3000x']\n",
      "Validation Images:\n",
      " ['20B5822  foto 13  3000x', '20B5020  foto 12  3000x', '20B3318  foto 2  3000x']\n",
      "Test Images:\n",
      " ['20B794  foto 12  3000x', '20B9593  foto 1  3000x']\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Images:\\n\", train_images)\n",
    "print(\"Validation Images:\\n\", valid_images)\n",
    "print(\"Test Images:\\n\", test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbeea0ed-8c76-4b26-8c1d-0f67245c6a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_patches, train_mask_patches = get_paths(image_patches, mask_patches, train_images)\n",
    "valid_img_patches, valid_mask_patches = get_paths(image_patches, mask_patches, valid_images)\n",
    "test_img_patches, test_mask_patches = get_paths(image_patches, mask_patches, test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc5e741",
   "metadata": {},
   "source": [
    "## III. Dataset and DataLoader\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "331765ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose(\n",
    "        [\n",
    "            A.Rotate(limit=45, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.GaussNoise(p=0.5)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c76eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_patches, train_mask_patches, transform = train_transform)\n",
    "valid_dataset = CustomDataset(valid_img_patches, valid_mask_patches, transform = None)\n",
    "test_dataset = CustomDataset(test_img_patches, test_mask_patches, transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a803cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train patches: 840\n",
      "Valid patches: 126\n",
      "Test patches: 84\n"
     ]
    }
   ],
   "source": [
    "print(\"Train patches:\", len(train_dataset))\n",
    "print(\"Valid patches:\", len(valid_dataset))\n",
    "print(\"Test patches:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82fe5103-2988-443c-ba3a-08a2672ada9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Hyperparameters \"\"\"\n",
    "batch_size = 2\n",
    "num_epochs = 50\n",
    "lr = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c106e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1\n",
    "    )\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34ed2c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420\n",
      "420.0\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "# printing train_loader length\n",
    "# it has to be len(train_dataset)/batch_size\n",
    "\n",
    "print(len(train_loader))\n",
    "print(len(train_dataset)/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d2e8e1",
   "metadata": {},
   "source": [
    "## IV. The Model\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f537b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Device used:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf205745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6be32f07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Architecture:\n",
      "\n",
      " build_unet(\n",
      "  (e1): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e2): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e3): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (e4): encoder_block(\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (b): conv_block(\n",
      "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (d1): decoder_block(\n",
      "    (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (d2): decoder_block(\n",
      "    (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (d3): decoder_block(\n",
      "    (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (d4): decoder_block(\n",
      "    (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv): conv_block(\n",
      "      (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (outputs): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to view model architecture\n",
    "print(\"Model Architecture:\\n\\n\", model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a51064c",
   "metadata": {},
   "source": [
    "## V. Loss function and Optimizer\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "caf7230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Cross Entropy -> Binary Semantic Segmentation\n",
    "# loss_fn = DiceBCELoss()\n",
    "\n",
    "# Categorical Cross Entropy -> Multiclass Semantic Segmentation\n",
    "# loss_fn = DiceLoss()\n",
    "\n",
    "# Categorical Cross Entropy\n",
    "loss_fn = CELoss()\n",
    "\n",
    "# Dealing with the imbalanced dataset\n",
    "# Caution! CELoss() weight has to be a tensor\n",
    "# loss_fn = CELoss(weight=[0.45620364, 1.97879363, 3.30427707])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f18c5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)#, weight_decay=0.1)\n",
    "\n",
    "# adjusting the learning rate based on the number of epochs by using a scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165dfb4",
   "metadata": {},
   "source": [
    "## VI. Saving the model\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ebce72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint path: files/2022_10_19_22_44_59_no_dropout_kfold_validation_fold_5.pth\n",
      "Loss file name: losses/2022_10_19_22_44_59_no_dropout_loss_fold_5.csv\n"
     ]
    }
   ],
   "source": [
    "# defining the checkpoint path to save the model weights\n",
    "timestr = time.strftime(\"%Y_%m_%d_%H_%M_%S_\")\n",
    "\n",
    "str = f\"no_dropout_lr_06_kfold_validation_fold_{i}.pth\"\n",
    "\n",
    "checkpoint_path = \"files/\" + timestr + str\n",
    "\n",
    "print(\"Checkpoint path:\", checkpoint_path)\n",
    "\n",
    "# defining a loss file to save the train and validation loss through time\n",
    "loss_file_name = f\"losses/{timestr}no_dropout_lr_06_loss_fold_{i}.csv\"\n",
    "\n",
    "print(\"Loss file name:\", loss_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7690395",
   "metadata": {
    "tags": []
   },
   "source": [
    "## VII. Training and evaluating the model\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a5d05b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Training function to calculate the training epoch loss \"\"\"\n",
    "def train(model, loader, optimizer, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # indicating that the model is training\n",
    "    # (important for dropout and batch_norm layers)\n",
    "    model.train()\n",
    "    \n",
    "    # going through all the batches in the loader\n",
    "    for x, y in loader:\n",
    "        # loading the images and the corresponding masks to the GPU device\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        y = y.to(device, dtype=torch.float32)\n",
    "        \n",
    "        # setting the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # making a prediction\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # finding the loss between the prediction and the ground truth\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        \n",
    "        # performing back propagation\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimizing the loss function using the optimizer\n",
    "        optimizer.step()\n",
    "        \n",
    "        # adding each batch loss to calculate later the average of all batches\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    # calculating the mean loss\n",
    "    epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "908228d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Validation function to calculate the validation epoch loss \"\"\"\n",
    "def evaluate(model, loader, loss_fn, device):\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    # turn off dropout, batch norm, etc. layers\n",
    "    # during model evaluation\n",
    "    model.eval()\n",
    "    \n",
    "    # turning off gradients computation\n",
    "    with torch.no_grad():\n",
    "        # going through all the batches in the loader\n",
    "        for x, y in loader:\n",
    "            # loading the images and the corresponding masks to the GPU device\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            y = y.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # making a prediction\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            # finding the loss between the prediction and the ground truth\n",
    "            loss = loss_fn(y_pred, y)\n",
    "\n",
    "            # adding each batch loss to calculate later the average of all batches\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        # calculating the mean loss\n",
    "        epoch_loss = epoch_loss/len(loader)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9603c16b-de34-4a6b-8c17-d7ca9c17c4ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\"\"\" Training the model \"\"\"\\n# Used as a checkpoint\\nbest_valid_loss = float(\"inf\")\\n\\ntrain_losses = []\\nvalid_losses = []\\nfor epoch in range(num_epochs):\\n    start_time = time.time()\\n\\n    train_loss = train(model, train_loader, optimizer, loss_fn, device)\\n    valid_loss = evaluate(model, valid_loader, loss_fn, device)\\n\\n\\n\\n    \"\"\" Saving the model \"\"\"\\n    if valid_loss < best_valid_loss:\\n        data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}\"\\n        print(data_str)\\n\\n        best_valid_loss = valid_loss\\n\\n        # Just to save the model\\n        # torch.save(model.state_dict(), checkpoint_path)\\n\\n        # Creating a checkpoint to save the best epoch\\n        # model state dict (weights & biases), optimizer state,\\n        # training losses and validation losses for printing purpose\\n\\n        checkpoint = {\\n            \"epoch\": epoch,\\n            \"model_state\": model.state_dict(),\\n            \"optim_state\": optimizer.state_dict(),\\n            \"train_losses\": train_losses,\\n            \"valid_losses\": valid_losses\\n        }\\n\\n        torch.save(checkpoint, checkpoint_path)\\n\\n\\n    # Scheduler to reduce lr if not improved after a number of epochs\\n    scheduler.step(valid_loss)\\n\\n    end_time = time.time()\\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\\n    data_str = f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n\"\\n    data_str += f\"\\tTrain Loss: {train_loss:.3f}\\n\"\\n    data_str += f\"\\tVal. Loss: {valid_loss:.3f}\\n\"\\n    print(data_str)\\n\\n    # Keep track of the train and validation loss\\n    # in order to plot them later\\n    train_losses.append(train_loss)\\n    valid_losses.append(valid_loss)\\n\\n\\n    # dictionary of lists  \\n    loss_dict = {\\'train_loss\\': train_losses, \\'val_loss\\': valid_losses}  \\n\\n    df = pd.DataFrame(loss_dict) \\n\\n    # saving the dataframe \\n    df.to_csv(loss_file_name)\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\"\"\" Training the model \"\"\"\n",
    "# Used as a checkpoint\n",
    "best_valid_loss = float(\"inf\")\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss = evaluate(model, valid_loader, loss_fn, device)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\" Saving the model \"\"\"\n",
    "    if valid_loss < best_valid_loss:\n",
    "        data_str = f\"Valid loss improved from {best_valid_loss:2.4f} to {valid_loss:2.4f}\"\n",
    "        print(data_str)\n",
    "\n",
    "        best_valid_loss = valid_loss\n",
    "\n",
    "        # Just to save the model\n",
    "        # torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "        # Creating a checkpoint to save the best epoch\n",
    "        # model state dict (weights & biases), optimizer state,\n",
    "        # training losses and validation losses for printing purpose\n",
    "\n",
    "        checkpoint = {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"optim_state\": optimizer.state_dict(),\n",
    "            \"train_losses\": train_losses,\n",
    "            \"valid_losses\": valid_losses\n",
    "        }\n",
    "\n",
    "        torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n",
    "    # Scheduler to reduce lr if not improved after a number of epochs\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    data_str = f\"Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\\n\"\n",
    "    data_str += f\"\\tTrain Loss: {train_loss:.3f}\\n\"\n",
    "    data_str += f\"\\tVal. Loss: {valid_loss:.3f}\\n\"\n",
    "    print(data_str)\n",
    "\n",
    "    # Keep track of the train and validation loss\n",
    "    # in order to plot them later\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "\n",
    "    # dictionary of lists  \n",
    "    loss_dict = {'train_loss': train_losses, 'val_loss': valid_losses}  \n",
    "\n",
    "    df = pd.DataFrame(loss_dict) \n",
    "\n",
    "    # saving the dataframe \n",
    "    df.to_csv(loss_file_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ea249",
   "metadata": {},
   "source": [
    "## VIII. Testing the model on the test data\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c797ab08-a8f5-49b7-a36a-5dc359cccae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, jaccard_score, precision_score, recall_score, classification_report, cohen_kappa_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aea5c59f-c6dd-4628-b927-1221313cfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \n",
    "    categories = [\"background\", \"podocytes\", \"gbm\"]\n",
    "    \n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    #y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    #y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    mean_score_jaccard = jaccard_score(y_true, y_pred, zero_division = 1, average=\"macro\")\n",
    "    per_class_jaccard = jaccard_score(y_true, y_pred, zero_division = 1, average=None)\n",
    "    \n",
    "    mean_score_f1 = f1_score(y_true, y_pred, zero_division = 1, average=\"macro\")\n",
    "    per_class_f1 = f1_score(y_true, y_pred, zero_division = 1, average=None)\n",
    "\n",
    "    mean_score_recall = recall_score(y_true, y_pred, zero_division = 1, average=\"macro\")\n",
    "    per_class_recall = recall_score(y_true, y_pred, zero_division = 1, average=None)\n",
    "\n",
    "    mean_score_precision = precision_score(y_true, y_pred, zero_division = 1, average=\"macro\")\n",
    "    per_class_precision = precision_score(y_true, y_pred, zero_division = 1, average=None)\n",
    "\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    \n",
    "    '''Calculate confusion matrix '''\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    '''Calculate FP, FN, TP, TN per class '''\n",
    "    FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "    FN = cm.sum(axis=1) - np.diag(cm)\n",
    "    TP = np.diag(cm)\n",
    "    TN = cm.sum() - (FP + FN + TP)\n",
    "    \n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    " \n",
    "    print(\"\\t\\t\\t background  podocytes  gbm\\n\")\n",
    "    print(\"mIoU\\t\\t\\t\", mean_score_jaccard)\n",
    "    print(\"per class IoU\\t\\t\", per_class_jaccard)\n",
    "    print(\"\\n\")\n",
    "    print(\"mean f1 score\\t\\t\", mean_score_f1)\n",
    "    print(\"per class f1 score\\t\", per_class_f1)\n",
    "    print(\"\\n\")\n",
    "    print(\"mean recall\\t\\t\", mean_score_recall)\n",
    "    print(\"per class recall\\t\", per_class_recall)\n",
    "    print(\"\\n\")\n",
    "    print(\"mean TNR\\t\\t\", np.mean(TNR))\n",
    "    print(\"per class TNR\\t\\t\", TNR)\n",
    "    print(\"\\n\")\n",
    "    print(\"mean precision\\t\\t\", mean_score_precision)\n",
    "    print(\"per class precision\\t\", per_class_precision)\n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy\\t\\t\", score_acc)\n",
    "    print(\"\\n\")\n",
    "    print(\"cohen's kappa\\t\\t\", kappa)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"classification report\")\n",
    "    print(classification_report(y_true, y_pred, target_names=categories))\n",
    "    \n",
    "    \n",
    "    print(\"confusion matrix:\\n\")\n",
    "    sns.heatmap(cm, annot=True, xticklabels=categories, yticklabels=categories)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    # print(\"True positives per class\", TP)\n",
    "    # print(\"True negatives per class\", TN)\n",
    "    # print(\"False positives per class\", FP)\n",
    "    # print(\"False negatives per class\", FN)\n",
    "\n",
    "    # return [mean_score_jaccard, score_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fa1b926-594b-4985-bb9a-beadf4052373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_parse(mask):\n",
    "    mask = np.expand_dims(mask, axis=-1)    ## (512, 512, 1)\n",
    "    mask = np.concatenate([mask, mask, mask], axis=-1)  ## (512, 512, 3)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "76909217-d81a-46b0-a6bf-1f2c068097fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset\\\\images\\\\20B794  foto 12  3000x.tif'\n",
      " '../dataset\\\\images\\\\20B9593  foto 1  3000x.tif']\n",
      "['../dataset\\\\masks_rgb\\\\20B794  foto 12  3000x - rgb_mask.png'\n",
      " '../dataset\\\\masks_rgb\\\\20B9593  foto 1  3000x - rgb_mask.png']\n"
     ]
    }
   ],
   "source": [
    "test_x = images[test_set]\n",
    "test_y = masks[test_set]\n",
    "\n",
    "print(test_x)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221f8c4e-7751-4487-8b98-787783a7f95d",
   "metadata": {},
   "source": [
    "### Loading the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14f7e63a-31a1-4f12-ab88-a6fbeb67bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the checkpoint file from the training process\n",
    "checκpoint_path = \"files/2022_10_17_02_04_37_no_dropout_kfold_validation_fold_5.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8fe5611c-d89b-4535-b904-b410f40329fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load the checkpoint file \"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = build_unet()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Loading the checkpoint \n",
    "checkpoint = torch.load(checκpoint_path)\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "optimizer.load_state_dict(checkpoint['optim_state'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss = checkpoint['train_losses']\n",
    "valid_loss = checkpoint['valid_losses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6409610e-4319-46a9-8cae-a7592a5367e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" UNet Hyperparameters \"\"\"\n",
    "H = 512\n",
    "W = 512\n",
    "size = (W, H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "07654aa3-5830-4c88-ae90-a5648116c284",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20B794  foto 12  3000x\n",
      "\n",
      "\n",
      "\t\t\t background  podocytes  gbm\n",
      "\n",
      "mIoU\t\t\t 0.5457539722013399\n",
      "per class IoU\t\t [0.74520179 0.43171082 0.46034931]\n",
      "\n",
      "\n",
      "mean f1 score\t\t 0.695845074541254\n",
      "per class f1 score\t [0.85400072 0.60306986 0.63046465]\n",
      "\n",
      "\n",
      "mean recall\t\t 0.7219198573505764\n",
      "per class recall\t [0.84053618 0.58176375 0.74345964]\n",
      "\n",
      "\n",
      "mean TNR\t\t 0.8390109810362055\n",
      "per class TNR\t\t [0.65693642 0.92710314 0.93299339]\n",
      "\n",
      "\n",
      "mean precision\t\t 0.6803949434987576\n",
      "per class precision\t [0.86790365 0.62599589 0.54728529]\n",
      "\n",
      "\n",
      "accuracy\t\t 0.7861354464576358\n",
      "\n",
      "\n",
      "cohen's kappa\t\t 0.5195610716078733\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.87      0.84      0.85   8019512\n",
      "   podocytes       0.63      0.58      0.60   1908792\n",
      "         gbm       0.55      0.74      0.63   1081744\n",
      "\n",
      "    accuracy                           0.79  11010048\n",
      "   macro avg       0.68      0.72      0.70  11010048\n",
      "weighted avg       0.79      0.79      0.79  11010048\n",
      "\n",
      "confusion matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 50%|██████████████████████████████████████████                                          | 1/2 [00:41<00:41, 41.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 20B9593  foto 1  3000x\n",
      "\n",
      "\n",
      "\t\t\t background  podocytes  gbm\n",
      "\n",
      "mIoU\t\t\t 0.5652411648702964\n",
      "per class IoU\t\t [0.81960806 0.23242981 0.64368562]\n",
      "\n",
      "\n",
      "mean f1 score\t\t 0.6870913455738052\n",
      "per class f1 score\t [0.9008622  0.37718953 0.78322231]\n",
      "\n",
      "\n",
      "mean recall\t\t 0.6381516632529269\n",
      "per class recall\t [0.95858605 0.27651942 0.67934952]\n",
      "\n",
      "\n",
      "mean TNR\t\t 0.7942773047059916\n",
      "per class TNR\t\t [0.42005431 0.96762453 0.99515308]\n",
      "\n",
      "\n",
      "mean precision\t\t 0.7891370460975263\n",
      "per class precision\t [0.84969549 0.59312275 0.9245929 ]\n",
      "\n",
      "\n",
      "accuracy\t\t 0.8366831824893043\n",
      "\n",
      "\n",
      "cohen's kappa\t\t 0.4729987411852634\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  background       0.85      0.96      0.90   8519182\n",
      "   podocytes       0.59      0.28      0.38   1605182\n",
      "         gbm       0.92      0.68      0.78    885684\n",
      "\n",
      "    accuracy                           0.84  11010048\n",
      "   macro avg       0.79      0.64      0.69  11010048\n",
      "weighted avg       0.82      0.84      0.82  11010048\n",
      "\n",
      "confusion matrix:\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [01:17<00:00, 38.61s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "time_taken = []\n",
    "\n",
    "for i, (x, y) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "    \"\"\"Extract the name \"\"\"\n",
    "    name = x.split(\"/\")[-1].split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    print(\"\\n\",name)\n",
    "\n",
    "    ''' Reading image and mask '''\n",
    "    image = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
    "    mask = cv2.imread(y, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Cropping the given image in order to have the right dimensions\n",
    "    # the following code is actually used only on new images\n",
    "    if image.shape != (3072, 3584):\n",
    "        image = image[:, 128:3712]\n",
    "        mask = mask[:, 128:3712]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    #print(image.shape)\n",
    "    #print(mask.shape)\n",
    "\n",
    "\n",
    "    mask = rgb2mask(mask)\n",
    "    #print(mask.shape)\n",
    "\n",
    "\n",
    "\n",
    "    ''' Creating patches of the image and the corresponding mask'''\n",
    "    patches_x = patchify(image, (512, 512), step=512)\n",
    "    #print(patches_x.shape)\n",
    "    patches_y = patchify(mask, (512, 512), step=512)\n",
    "    #print(patches_y.shape)\n",
    "\n",
    "    #pred_patches = np.empty(patches_y.shape)\n",
    "    #print(pred_patches.shape)\n",
    "    pred_patches = np.empty(patches_x.shape)\n",
    "    #print(pred_patches.shape)\n",
    "\n",
    "\n",
    "    for k in range(patches_x.shape[0]):\n",
    "        for l in range(patches_x.shape[1]):\n",
    "\n",
    "            x = np.expand_dims(patches_x[k, l, :, :], axis=0)                           # (1, 512, 512) \n",
    "            x = x/255.0\n",
    "            x = np.expand_dims(x, axis=0)                           # (1, 1, 512, 512) to create a batch (egw mallon den to xreiazomai)\n",
    "            #print(\"X_shape\", x.shape)\n",
    "            x = x.astype(np.float32)\n",
    "            x = torch.from_numpy(x)\n",
    "            x = x.to(device)\n",
    "\n",
    "\n",
    "            y = np.expand_dims(patches_y[k, l, :, :], axis=0)            # (1, 512, 512)\n",
    "            #y = np.expand_dims(y, axis=0)               # (1, 1, 512, 512) to create a batch\n",
    "            y = torch.from_numpy(y)\n",
    "            y = y.to(device)\n",
    "            #print(y.shape)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                \"\"\" Prediction and Calculating FPS \"\"\"\n",
    "                start_time = time.time()\n",
    "                pred_y = model(x)\n",
    "\n",
    "\n",
    "                # we need a softmax to get a mask as an output\n",
    "                pred_y = torch.softmax(pred_y, dim=1)\n",
    "                #print(pred_y.shape)\n",
    "                pred_y = torch.argmax(pred_y, dim=1)\n",
    "                #pred_y = np.expand_dims(pred_y, axis=0)\n",
    "                #print(pred_y.shape)\n",
    "\n",
    "\n",
    "                total_time = time.time() - start_time\n",
    "                time_taken.append(total_time)\n",
    "\n",
    "                #score = calculate_metrics(y, pred_y)\n",
    "                #metrics_score = list(map(add, metrics_score, score))\n",
    "                pred_y = pred_y.cpu().numpy()           ## (1, 512, 512)\n",
    "                #pred_y = pred_y * 255 // 2\n",
    "                pred_y = np.squeeze(pred_y, axis=0)     ## (512, 512)\n",
    "                pred_y = np.array(pred_y, dtype=np.uint8)\n",
    "\n",
    "                ''' Saving the predicted patch to reconstruct the image at the next step '''\n",
    "                pred_patches[k, l, :, :] = pred_y\n",
    "\n",
    "\n",
    "            \"\"\" Saving masks \"\"\"\n",
    "            # (512, 512) -> (3, 512, 512)\n",
    "            image_3channel = mask_parse(patches_x[k, l, :, :])\n",
    "            ori_mask = mask_parse(patches_y[k, l, :, :])\n",
    "            pred_y = mask_parse(pred_patches[k, l, :, :])\n",
    "            line = np.ones((size[1], 10, 3)) * 128\n",
    "\n",
    "            #print(image_3channel.shape, ori_mask.shape, pred_y.shape)\n",
    "\n",
    "\n",
    "            #print(np.unique(pred_y))\n",
    "\n",
    "            cat_images = np.concatenate(\n",
    "                [image_3channel, line, ori_mask * 255 // 2, line, pred_y * 255 // 2], axis=1\n",
    "            )\n",
    "\n",
    "            # Creating an image where original image, ground truth and prediction \n",
    "            # are side by side to visualize and compare the results\n",
    "            \n",
    "            cv2.imwrite(f\"results/{name}\" + \"_\" + k.__str__() + \"_\" + l.__str__() +\".png\", cat_images)\n",
    "\n",
    "    reconstructed_image = unpatchify(pred_patches * 255 // 2, image.shape)\n",
    "    #reconstructed_image = mask_parse(reconstructed_image)\n",
    "    #print(reconstructed_image.shape)\n",
    "    cv2.imwrite(f\"results_no_patches/{name}.png\", reconstructed_image)\n",
    "    #cv2.imwrite(f\"results_no_patches/{name}.png\", reconstructed_image)\n",
    "\n",
    "\n",
    "    pred_mask = unpatchify(pred_patches, image.shape)\n",
    "\n",
    "\n",
    "    score = calculate_metrics(mask, pred_mask)\n",
    "    #print(score)\n",
    "\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81a84e-90fc-474e-aca6-e7e223f8c85e",
   "metadata": {},
   "source": [
    "## IX. Results\n",
    "[Back](#Thesis:-Segmentation-of-Electron-Microscopy-Kidney-Biopsy-Images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "821a9eaff0514b604ac65ccf05f07f24497f535bd8a55e4b1375df66e8103be2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
